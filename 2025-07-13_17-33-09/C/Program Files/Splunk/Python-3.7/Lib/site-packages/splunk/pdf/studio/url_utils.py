import base64
import mimetypes
from urllib.parse import urlparse
import requests

from splunk.appserver.mrsparkle.controllers.view import (
    REQUIRED_DASHBOARD_STUDIO_CSP_DIRECTIVES,
    REQUIRED_DASHBOARD_STUDIO_CSP_VALUES,
    TRUSTED_DOMAIN_PREFIXES
)
from splunk.appserver.mrsparkle.lib.util import extract_csp_header, extract_trusted_domains


def isRelativeUrl(url):
    """
    is this a relative url
    """
    return not bool(urlparse(url).netloc)


def isUrlAllowed(url, trustedDomains):
    """
    is the url relative or allowed by the trusted domains
    """
    return isRelativeUrl(url) or isUrlAllowedByTrustedDomains(url, trustedDomains)


def isUrlAllowedByTrustedDomains(url, trustedDomains):
    """
    Tests a url to see if it matches an entry in the trustedDomain array. Defaults to false.

    Example:

    invalidUrl = 'https://not-splunk.com';
    allowableUrl = 'https://example.splunk.com';

    # False
    isUrlAllowedByTrustedDomains(invalidUrl, ['*.splunk.com'])

    # True
    isUrlAllowedByTrustedDomains(allowableUrl, ['*.splunk.com'])
    """
    if '*' in trustedDomains:
        return True
    if 'none' in trustedDomains:
        return False

    try:
        validatedUrl = urlparse(url)
    except:
        return False

    isAllowed = False

    for domain in trustedDomains:
        if domain is None:
            continue

        startsWithHttps = domain.startswith('https:')
        startsWithHttp = domain.startswith('http:')

        if (startsWithHttps or startsWithHttp) and not '*' in domain:
            isAllowed = url.startswith(domain)
        elif startsWithHttps:
            parts = domain.split('*')

            # not a valid use of *
            if parts[0] != 'https://' or len(parts) < 2:
                continue

            isAllowed = validatedUrl.hostname.endswith(
                parts[1]) and validatedUrl.scheme == 'https'
        elif startsWithHttp:
            parts = domain.split('*')

            # not a valid use of *
            if parts[0] != 'http://' or len(parts) < 2:
                continue

            isAllowed = validatedUrl.hostname.endswith(
                parts[1]) and validatedUrl.scheme == 'http'
        elif domain.startswith('*'):
            isAllowed = validatedUrl.hostname.endswith(domain[1:])
        elif '/' in domain:
            index = domain.index('/')
            domainHost = domain[0:index]
            domainPath = domain[index:]
            isAllowed = validatedUrl.hostname == domainHost and validatedUrl.path.startswith(
                domainPath)
        else:
            isAllowed = validatedUrl.hostname.startswith(domain)

        # if we've found a match, no need to check the rest of the trusted list
        if isAllowed:
            break

    return isAllowed


def extractCSPAndTrustedDomains(dashboards_csp_settings):
    """
    returns the csp_header and the trusted domains list from the feature:dashboards_csp web.conf setting
    """
    csp_header = ''
    trustedDomains = None

    enableContentRestrictions = dashboards_csp_settings[
        'enable_dashboards_external_content_restriction']
    if enableContentRestrictions is True:
        trustedDomains = extract_trusted_domains(dashboards_csp_settings, TRUSTED_DOMAIN_PREFIXES)
        csp_header = extract_csp_header(
            REQUIRED_DASHBOARD_STUDIO_CSP_VALUES,
            dashboards_csp_settings,
            REQUIRED_DASHBOARD_STUDIO_CSP_DIRECTIVES,
            TRUSTED_DOMAIN_PREFIXES,
            True
        )

    return csp_header, trustedDomains


def getDataURIForExternalImage(url, trustedDomains=None):
    """
    return a base64 encoded data URI. Uses the urls content-type for the image type.

    if trustedDomains is present we check the url against that to ensure it's allowed
    """
    try:
        # is url allowed
        if trustedDomains and not isUrlAllowed(url, trustedDomains):
            return None

        # do we have a valid response
        response = requests.get(url, timeout=10)
        if (not response.ok or not response.content):
            return None

        # base64 encode the data
        content = base64.b64encode(response.content)

        # get content_type from the headers or guessing
        if response.headers and 'content-type' in response.headers:
            content_type = response.headers["content-type"]
        else:
            content_type, _extension = mimetypes.guess_type(url)

        # fallback to image/png
        if content_type is None:
            content_type = 'image/png'

        return "data:{};base64,{}".format(content_type, content.decode('utf-8'))
    except Exception:
        return None
